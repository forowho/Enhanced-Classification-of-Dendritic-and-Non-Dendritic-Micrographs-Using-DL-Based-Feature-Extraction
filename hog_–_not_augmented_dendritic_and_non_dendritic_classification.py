# -*- coding: utf-8 -*-
"""HOG â€“ Not Augmented Dendritic and non_Dendritic Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BBmA7VA_iWH699Xf8Kiv5WpNK-zsXzNN
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import skimage.io
import os
import keras
import os
import glob

# %matplotlib inline
import shutil
from shutil import copyfile
import random
import time
import cv2
import tensorflow as tf
from tensorflow.keras.preprocessing import image

from skimage.feature import hog
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier as KNeighborClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

"""# Import dataset from source website"""

# Download dataset
!wget https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/nyb6mycvfd-1.zip

#unzip the dataset
!unzip -q /content/nyb6mycvfd-1.zip

# tensorflow Libraries
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
# from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tensorflow.keras.utils import array_to_img, img_to_array, load_img
#from tensorflow.keras.utils import ImageDataGenerator, array_to_img, img_to_array, load_img
datagen = ImageDataGenerator(rotation_range =15,
                         width_shift_range = 0.2,
                         height_shift_range = 0.2,
                         rescale=1./255,
                         shear_range=0.2,
                         zoom_range=0.2,
                         horizontal_flip = True,
                         fill_mode = 'nearest',
                         data_format='channels_last',
                         brightness_range=[0.5, 1.5])

# set path to dendritic micrograph images
dendritic_dir = '/content/Dendritic'
# set path to non dendritic micrograph images
non_dendritic_dir = '/content/Non-Dendritic'

#Print the total number of images in each directory
print("The total number of dendritic images are", len(os.listdir(dendritic_dir)))
print("The total number of non dendritic images are", len(os.listdir(non_dendritic_dir)))

"""Step 2: Features extraction with histogram of oriented gradient (HOG)"""

# Paths to the dataset
dendritic_folder = "/content/Dendritic"
non_dendritic_folder = "/content/Non-Dendritic"

def extract_hog_features(image):
    # Convert the image to grayscale for HOG
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # Resize the image to a fixed size for consistent HOG feature size
    resized_image = cv2.resize(gray_image, (64, 64)) # Resize to 64x64
    # Extract HOG features
    features, hog_image = hog(resized_image, orientations=9, pixels_per_cell=(8, 8),
                            cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')
    return features

def load_dataset_and_extract_features():
    data = []
    labels = []
    # Process dendritic images
    for img_name in os.listdir(dendritic_folder):
        img_path = os.path.join(dendritic_folder, img_name)
        image = cv2.imread(img_path)
        if image is not None:
            features = extract_hog_features(image)
            data.append(features)
            labels.append(1)  # 1 for Dendritic
    # Process non-dendritic images
    for img_name in os.listdir(non_dendritic_folder):
        img_path = os.path.join(non_dendritic_folder, img_name)
        image = cv2.imread(img_path)
        if image is not None:
            features = extract_hog_features(image)
            data.append(features)
            labels.append(0)  # 0 for Non-Dendritic
    return np.array(data), np.array(labels)

"""#Step 4: Train Test Split"""

X, Y = load_dataset_and_extract_features()

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify = Y, random_state=42)

print(X.shape, X_train.shape, X_test.shape)

"""#Step 5: Comparing the performance of models
* LogisticRegression()
* SVC(kernel='linear')
* KNeighborClassifier()
* RandomForestClassifier()

# Model comparison
"""

# Metrics Libraries
from sklearn.metrics import confusion_matrix, accuracy_score, recall_score
from sklearn.metrics import precision_score, f1_score, ConfusionMatrixDisplay
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

models = [LogisticRegression(max_iter=1000), SVC(kernel='linear'), KNeighborClassifier(), RandomForestClassifier()]

def plot_confusion_matrix(y_val, y_pred, label):
    '''function to plot confusion matrix

    Args
    y_val: array. The validation set of the target variable.
    y_pred: array. Model's prediction.
    label: list. A list containing all the classes in the target variable

    Returns
    It returns a plot of the confusion matrix
    '''
    cm = confusion_matrix(y_val, y_pred)
    fig, ax = plt.subplots(figsize=(5,5))
    ConfusionMatrixDisplay(cm, display_labels=label).plot(ax=ax, values_format='', xticks_rotation='vertical')
    plt.show()

# class labels
label = ['Non-Dendritic', 'Dendritic']
RANDOM_STATE = 1

def compare_models_train_test():
  for model in models:
    # Train the model
    model.fit(X_train, y_train)

    # Evaluate the model on training data
    train_predictions = model.predict(X_train)
    train_accuracy = accuracy_score(y_train, train_predictions)
    train_accuracy = train_accuracy*100
    train_accuracy = round(train_accuracy, 2)
    print(f"Training Accuracy for {model}: {train_accuracy}%")

    # Evaluate the model on validation data
    val_predictions = model.predict(X_test)
    val_accuracy = accuracy_score(y_test, val_predictions)
    val_accuracy = val_accuracy*100
    val_accuracy = round(val_accuracy, 2)
    print(f"Validation Accuracy for {model}: {val_accuracy}%")

    # Confusion matrix
    plot_confusion_matrix(y_test, val_predictions, label)
    print(classification_report(y_test, val_predictions))

compare_models_train_test()